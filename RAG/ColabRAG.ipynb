{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ffedef",
   "metadata": {},
   "source": [
    "### Installation of dependency not built-in Google Colab\n",
    "\n",
    "Byaldi==0.0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cb26c",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!pip install Byaldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e37fbf",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!apt-get install -y poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cccfd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from byaldi import RAGMultiModalModel\n",
    "#from together import Together\n",
    "from openai import OpenAI\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# Définir les chemins\n",
    "model_name = \"vidore/colqwen2-v0.1\"\n",
    "local_model_dir = Path(\"./models\") / model_name.replace(\"/\", \"_\")\n",
    "index_name = \"onisr_index\"\n",
    "#pdf_path = Path(\"./content/pdf_folder/Codedelaroute.pdf\")\n",
    "\n",
    "pdf_path = Path(\"./content/pdf_folder/repport2024.pdf\")\n",
    "images_dir = Path(\"./content/images\")\n",
    "\n",
    "# Initialiser le client OpenAI\n",
    "client = OpenAI(\n",
    "    api_key='c4bf084df6c344eb437607fb0f04ea627d17bbc84eb5ab1c621f874d36ec3b1b',\n",
    "    base_url=\"http://10.3.0.3:23333/v1\"\n",
    ")\n",
    "\n",
    "# Créer les répertoires si nécessaire\n",
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# 1. Charger ou télécharger le modèle\n",
    "if local_model_dir.exists() and any(local_model_dir.iterdir()):\n",
    "    print(f\"Chargement du modèle local depuis {local_model_dir}\")\n",
    "    model = RAGMultiModalModel.from_pretrained(str(local_model_dir))\n",
    "else:\n",
    "    print(f\"Téléchargement du modèle {model_name}\")\n",
    "    model = RAGMultiModalModel.from_pretrained(model_name)\n",
    "    print(dir(model))\n",
    "    # Sauvegarder le modèle localement pour une utilisation future\n",
    "    #model.save_pretrained(str(local_model_dir))\n",
    "\n",
    "# 2. Vérifier si l'index existe déjà\n",
    "index_path = Path(f\"./{index_name}\")\n",
    "if index_path.exists():\n",
    "    print(f\"Chargement de l'index existant depuis {index_path}\")\n",
    "    model.load_index(index_name=index_name, index_path=str(index_path))\n",
    "else:\n",
    "    print(f\"Création d'un nouvel index pour {pdf_path}\")\n",
    "    model.index(input_path=pdf_path,\n",
    "                index_name=index_name,\n",
    "                store_collection_with_index=True,\n",
    "                overwrite=True)\n",
    "\n",
    "# 3. Convertir le PDF en images une seule fois\n",
    "if not any(images_dir.iterdir()):\n",
    "    print(f\"Conversion du PDF en images et sauvegarde dans {images_dir}\")\n",
    "    images = convert_from_path(pdf_path)\n",
    "    for i, image in enumerate(images):\n",
    "        image.save(images_dir / f\"page_{i+1}.png\", \"PNG\")\n",
    "else:\n",
    "    print(f\"Images déjà présentes dans {images_dir}, chargement direct\")\n",
    "\n",
    "# Requête de recherche\n",
    "query = \"Quelle est le sexe qui fait le plus d'accident ?\"\n",
    "results = model.search(query, k=1)\n",
    "\n",
    "print(f\"Résultats de la recherche pour '{query}':\")\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")\n",
    "\n",
    "# Charger l'image de la page retournée\n",
    "page_num = model.search(query, k=1)[0].page_num\n",
    "image_path = images_dir / f\"page_{page_num}.png\"\n",
    "\n",
    "# Lire l'image en base64\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    import base64\n",
    "    returned_page = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Appel à l'API Together\n",
    "#client = Together(api_key='c4bf084df6c344eb437607fb0f04ea627d17bbc84eb5ab1c621f874d36ec3b1b')\n",
    "\n",
    "model_name = client.models.list().data[0].id\n",
    "print(f\"Modèle utilisé : {model_name}\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": query},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{returned_page}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=200,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
